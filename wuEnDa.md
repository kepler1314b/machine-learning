####监督学习

+ 有明确的分类特征，已经给出

#### 无监督学习

实现并不知道数据集中的数据具体什么类别

+ 聚类算法（cluster）: 将不同的数据进行分类（daujian自己找特征，分类）
+ 鸡尾酒会算法： 分离声音（多个不同位置麦克风录音）

####代价函数

例如在线性回归中 目的是找到假设函数使所有数据集尽量的拟合，即求一个最小化差距的函数的最优解 如$\frac{1}{2m}\sum ^m_ {i=1}(h(x_i)-y_i)^2$ ，前面的系数不会对结果造成影响，只是为了方便求导，前面的这个最小化差距的函数（平方误差代价函数**越小越精确**）就是关于$\theta_0 \theta_1$的代价函数，一般用$J(\theta_0,\theta_1)$表示

对于大多数线性回归问题，平方误差代价函数一般不错

假设函数$h_\theta(x)=\theta_0+\theta_1x$   

#### 梯度下降

利用梯度下降法可以求需要最小化函数的参数，不仅仅是用于代价函数

给定任意初值然后不断改变参数，接近或求出最优解，多个参数要同时进行更新



 